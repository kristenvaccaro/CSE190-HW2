{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": false,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": false,
      "toc_window_display": false
    },
    "colab": {
      "name": "Week_2_Understanding_Models.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HhoaZMxrZXZ"
      },
      "source": [
        "# Home Loan Prediction\n",
        "The last assignment explored datasets related to home loan applications in San Diego county. Now we will train a machine learning model to predict whether to accept or reject a loan application.\n",
        "\n",
        "**Your goal in this assignment is to explore different kinds of explanations of machine learning models.**\n",
        "\n",
        "\n",
        "## Part 1: Building a Model\n",
        "\n",
        "Upload the .zip file ('data.zip') included in the homework assignment. I **strongly** recommend using the following code rather than the Colab web interface for uploading files, particularly for those with slower internet connections. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bduXgr6K4QF5"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rH4-NUYa4im1"
      },
      "source": [
        "import zipfile\n",
        "import io\n",
        "zf = zipfile.ZipFile(io.BytesIO(uploaded['data.zip']),\"r\")\n",
        "zf.extractall()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A95MpbULaY4G"
      },
      "source": [
        "We will use a new home_loans.csv dataset.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0ZlYOlqZJEd"
      },
      "source": [
        "import pandas as pd # import pandas library\n",
        "df = pd.read_csv('data/home_loans.csv', low_memory=False) # read the csv file into a pandas dataframe object"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cBnoAJtSIW5"
      },
      "source": [
        "### Balance the Data\n",
        "\n",
        "First, we know from last week's assignment that most loans are approved. But we'll often get better performance overall with \"balanced\" data sets (that is, an equal number of approved and denied applications). Otherwise, we can run into problems, where we always predict that the loan should be approved."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bT6I-Yz8SUNP"
      },
      "source": [
        "# First take the maximum rows with loan_approved == 0\n",
        "zeros = df.loc[df[\"loan_approved\"] == 0]\n",
        "# Get all rows with loan_approved == 1\n",
        "all_ones = df.loc[df[\"loan_approved\"] == 1]\n",
        "\n",
        "# Take a random sample of 28220 loans that have been approved (same as the number rejected)\n",
        "num_rejected_applications = zeros.shape[0]\n",
        "ones = all_ones.sample(n=num_rejected_applications, random_state = 1)\n",
        "print('zeros:   ', zeros.shape)\n",
        "print('ones:    ', ones.shape)\n",
        "\n",
        "# Create the balanced data set by combining both sets of zeros and ones that have the same number of rows\n",
        "balanced_data = zeros.append(ones, ignore_index=True)\n",
        "print('balanced:', balanced_data.shape)\n",
        "print(balanced_data.loan_approved.value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SST2-iyfonm-"
      },
      "source": [
        "### Separate Input and Outputs\n",
        "\n",
        "Next, we want to split the data into two separate dataframes. One dataframe will hold the data that we want to use to predict whether we should approve the loan application (`X`). \n",
        "\n",
        "The other dataframe should hold the data about the actual approval decisions that were previously made by humans (`y`). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNYluuU5pN2n"
      },
      "source": [
        "input_columns = balanced_data.columns.drop(labels=['denial_reason', 'loan_approved'])\n",
        "X = balanced_data[input_columns]\n",
        "y = balanced_data['loan_approved']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rE9m4U6zGvBD"
      },
      "source": [
        "### Focus on Financial Data\n",
        "We exclude all of the non-financial columns: race/ethnicity, gender, town name, etc. All that is left in `X` is financial information about the application. _If you wish to include any of the categorical variables for training, ensure you use a one-hot encoding. Details below._\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vz7fAKNeN7bQ"
      },
      "source": [
        "input_columns = X.columns.drop(labels=['co_applicant_sex',\n",
        "       'co_applicant_race', 'applicant_sex', 'applicant_race','is_hoepa_loan', 'occupied_by_owner','town_name','loan_purpose_name'])\n",
        "X = X[input_columns]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txage8NWN9sR"
      },
      "source": [
        "We can also create new data. For example, calculating the applicant's debt-to-income ratio."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jueidoXpFg0S"
      },
      "source": [
        "X['debt_income_ratio'] = (X['loan_amount_000s']+X['existing_debt_000s'])/X['applicant_income_000s']\n",
        "input_columns = X.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19pCU84lAqJH"
      },
      "source": [
        "_OPTIONAL: If you wanted to include any categorical variables, you need to use a one-hot encoding to represent them in a way that the logistic regression model can deal with._\n",
        "\n",
        "```\n",
        "categorical_features = ['loan_purpose_name', 'town_name']\n",
        "X_categorical = balanced_data[categorical_features]\n",
        "\n",
        "enc = preprocessing.OneHotEncoder()\n",
        "enc.fit(X_categorical) # fit the encoder to categories in our data \n",
        "one_hot = enc.transform(X_categorical) # transform data into one hot encoded sparse array format\n",
        "\n",
        "# Finally, put the newly encoded sparse array back into a pandas dataframe so that we can use it\n",
        "X_cat = pd.DataFrame(one_hot.toarray(), columns=enc.get_feature_names())\n",
        "X = pd.concat([X, X_cat], axis=1, sort=False)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wnB23fL2Beq"
      },
      "source": [
        "### Create Training/Test Splits\n",
        "\n",
        "Next, we will split the data into a training set and a test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdpPy6_whvBN"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWTwxJqdU923"
      },
      "source": [
        "### Preprocess Numerical Data (Scaling)\n",
        "\n",
        "We preprocess the data using [`sklearn.preprocessing`](https://scikit-learn.org/stable/modules/preprocessing.html). \n",
        "\n",
        "We normalize any continous numerical features, such as loan dollar amount, to have zero mean and unit variance. This process will ensure that the average of that feature, such as the average amount that a person asks for in loan amount, is scaled to 0. Values less than the average will be negative numbers, and values larger than the average will be positive numbers. You can consider other approaches, as detailed in the `sklearn.preprocessing` documentation.\n",
        "\n",
        "To avoid learning anything from your testing data set, this normalization should be learned only with the training data. Once the scaler is learned, you can apply it to the test data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6P98WSNMPbv6"
      },
      "source": [
        "from sklearn import preprocessing # import preprocessing utilites\n",
        "scaler = preprocessing.StandardScaler().fit(X_train)\n",
        "print('Max income - unscaled:    ', X_train['applicant_income_000s'].max())\n",
        "print('Std income - unscaled:    ', X_train['applicant_income_000s'].std())\n",
        "X_scaled = scaler.transform(X_train)\n",
        "X_train = pd.DataFrame(X_scaled, columns=input_columns)\n",
        "X_test = pd.DataFrame(scaler.transform(X_test), columns=input_columns)\n",
        "print('Max income - scaled:      ', X_train['applicant_income_000s'].max())\n",
        "print('Std income - scaled:      ', X_train['applicant_income_000s'].std())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3wr0IcPrZXf"
      },
      "source": [
        "### Train the Model\n",
        "\n",
        "We will use [scikit learn](https://scikit-learn.org/stable/index.html) to build our machine learning model. We train a logistic regression classifier on the training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsIvAbQbPqfQ"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "model = LogisticRegression(solver='lbfgs').fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bWNOQB-koIV"
      },
      "source": [
        "### Analyze Performance\n",
        "\n",
        "Now we can calculate the accuracy on the training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGywz40SlP18"
      },
      "source": [
        "predictions = model.predict(X_train)\n",
        "accuracy = sum(predictions==y_train)/len(y_train)\n",
        "'The accuracy on the training set is about {}%'.format(round(accuracy*100, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ow5emCJprZXg"
      },
      "source": [
        "### Question 1: What is the accuracy of our model on the test set?\n",
        "_Double click to write your answer question here. Show your work in code below if applicable._"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnZq58cVEz4E"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AilZ0niya-d7"
      },
      "source": [
        "## Part 2: Understanding Individual Predictions\n",
        "\n",
        "### Question 2.A: Suppose this model were used to automatically approve or deny loan applications. What are 3 questions that someone might have about the model if it denied their loan application?\n",
        "\n",
        "_Double click to write your answer question here. Show your work in code below if applicable._\n",
        "\n",
        "\n",
        "1.   \n",
        "2.   \n",
        "3.   \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_5e9D7ZnUG_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQtzXJapJD4M"
      },
      "source": [
        "Let's look at one of the loan applications from the test set that our model would deny."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X60CUrlLJOXC"
      },
      "source": [
        "application = X_test[model.predict(X_test)==0].iloc[[0]]\n",
        "application"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGA7esTnFmw9"
      },
      "source": [
        "### Question 2.B: Why do you think this application was denied? \n",
        "_Double click to write your answer question here. Show your work in code below if applicable._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duLQvDp5VB-P"
      },
      "source": [
        "You might find it useful to see the model weights, accessible with `model.coef_`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYcBldPNXG6H"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nc545ftxdhU_"
      },
      "source": [
        "### Question 2.C: What would you tell this applicant if they asked how to get approved? What would happen if this applicant's income doubled (but everything else stayed the same)? Would the model approve this new application? What about tweaking other feature's values? \n",
        "\n",
        "Note: While \"building a model,\" we spent most of our time pre-processing the data in various ways. Do you need to transform the data/values/predictions in any way before showing it to users?\n",
        "\n",
        "_Double click to write your answer question here. Show your work in code below if applicable._"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDuQCqv8aAoS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2DqKKOyflzA"
      },
      "source": [
        "### Question 2.D: Imagine that you are designing a tool that shows applicants the model's output for their application and displays some additional information explaining the model's output. Sketch three different versions of what this tool might look like. These sketches can be rough. \n",
        "\n",
        "_Attach a pdf with your sketches. Please include any annotations/description on the pdf itself (not in this notebook)._"
      ]
    }
  ]
}
